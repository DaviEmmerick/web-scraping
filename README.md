# ğŸ“Œ Web Scraping com Python

Este projeto Ã© um scraper em Python que coleta notÃ­cias do site G1 Globo e armazena os dados extraÃ­dos em um banco de dados SQLite. O script utiliza a biblioteca BeautifulSoup para fazer o parsing do HTML da pÃ¡gina, a biblioteca requests para realizar as requisiÃ§Ãµes HTTP e sqlite3 para interagir com o banco de dados local.

O scraper extrai os seguintes dados das notÃ­cias:

TÃ­tulo: O tÃ­tulo da notÃ­cia.

Link: O URL da notÃ­cia.

Esses dados sÃ£o entÃ£o salvos em um banco de dados SQLite, armazenado no diretÃ³rio /app/data dentro do contÃªiner Docker.

# ğŸ› ï¸ Funcionalidades

â€¢ ExtraÃ§Ã£o de notÃ­cias: O scraper coleta os links e tÃ­tulos das notÃ­cias mais recentes do site G1.

â€¢ Armazenamento em banco de dados SQLite: Os dados sÃ£o armazenados em uma tabela chamada news dentro do banco de dados news.db.

â€¢ Ambiente Dockerizado: O projeto estÃ¡ configurado para rodar em um contÃªiner Docker, com volumes que permitem persistÃªncia dos dados no host.

# âœï¸ Tecnologias Utilizadas

â€¢ Python: Linguagem principal do projeto.

â€¢ Requests: Para realizar as requisiÃ§Ãµes HTTP.

â€¢ BeautifulSoup: Para fazer o parsing do HTML e extrair os dados.

â€¢ SQLite: Para armazenar os dados extraÃ­dos.

â€¢ Docker: Para facilitar a execuÃ§Ã£o do projeto em um ambiente isolado.

## ğŸš€ Como Rodar o Projeto

1ï¸âƒ£ Clone o repositÃ³rio:

```bash
git clone <URL_DO_REPOSITORIO>
cd <DIRETORIO_DO_REPOSITORIO>
```

2ï¸âƒ£ Construa e execute o contÃªiner Docker:

```bash

docker-compose up --build
```
3ï¸âƒ£ O scraper irÃ¡ rodar automaticamente e armazenar os dados em /app/data/news.db dentro do contÃªiner.

# Estrutura do Projeto

â€¢ scraping/: ContÃ©m o cÃ³digo do scraper.

â€¢ data/: Pasta onde o banco de dados news.db serÃ¡ armazenado.

â€¢ docker-compose.yml: ConfiguraÃ§Ã£o do Docker Compose para rodar o contÃªiner.

â€¢ scraper.py: Script principal que executa o scraping e salva as notÃ­cias no banco de dados.

# âœ¨ ImplementaÃ§Ãµes Futuras

-> Provavelmente eu vou tentar automatizar esse processe de alguma forma diferente, talvez com Prefect ou Airflow. 
-> Caso eu faÃ§a isso, vou migrar o banco de dados para o PostgreSQL.

# ğŸ“„ LiÃ§enca

Este projeto estÃ¡ sob a licenÃ§a MIT. Consulte o arquivo LICENSE para mais detalhes.